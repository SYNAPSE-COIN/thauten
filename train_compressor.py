"""Symbolic Compression Training Routine

This module provides a staged GRPO-based training pipeline for symbolic compression and recovery
using the verifiers setup. Each phase applies targeted prompt templates with placeholder tags.

=== TRAINING PHASES & PROMPTS ===

Phase 1: Identity (Î±=0.005, Î²=3.0) - Emphasis on accuracy
â”œâ”€â”€ prompts/identity_compression.txt     â†’ {content}
â”œâ”€â”€ prompts/identity_decompression.txt   â†’ {compressed}
â””â”€â”€ prompts/evaluation.txt               â†’ {original}, {restored}

Phase 2: Structured (Î±=0.02, Î²=2.0) - Learn abbreviations/symbol systems
â”œâ”€â”€ prompts/structured_compression.txt   â†’ {content}
â”œâ”€â”€ prompts/structured_decompression.txt â†’ {compressed}
â””â”€â”€ prompts/evaluation.txt               â†’ {original}, {restored}

Phase 3: Freeform (Î±=0.05, Î²=1.5) - Develop symbolic style
â”œâ”€â”€ prompts/freeform_compression.txt     â†’ {content}
â”œâ”€â”€ prompts/freeform_decompression.txt   â†’ {compressed}
â””â”€â”€ prompts/evaluation.txt               â†’ {original}, {restored}

Phase 4: Cognition (Î±=0.1, Î²=1.0) - Reasoning with compression priority
â”œâ”€â”€ prompts/cognition_compression.txt    â†’ {content}
â”œâ”€â”€ prompts/cognition_decompression.txt  â†’ {compressed}
â””â”€â”€ prompts/evaluation.txt               â†’ {original}, {restored}

=== PROMPT TAG SOURCES ===

{content}       â† Sample text from dataset
                  â€¢ agentlans/wikipedia-paragraphs (phases 1â€“3)
                  â€¢ willcb/gsm8k-python-test (phase 4, mapped to 'text' field)

{compressed}    â† Result from compression rollout
                  â€¢ Extracted from <compress>...</compress> sections
                  â€¢ Input for decompression rollout

{original}      â† Initial dataset text
                  â€¢ Identical to {content}, preserved for scoring

{restored}      â† Output from decompression rollout
                  â€¢ Extracted from <decompress>...</decompress> sections
                  â€¢ Compared against {original} for fidelity

=== EXECUTION FLOW ===

For each dataset example:
1. Compression:        {content} â†’ compression_prompt â†’ <compress>result</compress>
2. Decompression:      {compressed} â†’ decompression_prompt â†’ <decompress>result</decompress>
3. Evaluation:         {original} + {restored} â†’ evaluation_prompt â†’ fidelity_score
4. Reward Function:    reward = base_score - Î±Ã—tokens - Î²Ã—(1-fidelity)
5. Both steps receive identical reward for gradient updates

=== PROMPT FORMATS ===

Supported formats:
â€¢ Legacy: Plain string templates with {tag} substitutions
â€¢ Conversation: Dialogue format using <|im_start|>role...content<|im_end|>

Format is auto-detected via "# Multi-turn conversation format" marker.
"""
import logging
from synapse.main import main

logger = logging.getLogger("synapse")

if __name__ == "__main__":
    main(
        "ğŸ§  Symbolic Compressor Training",
        default_model="",
        default_data=""
    )

