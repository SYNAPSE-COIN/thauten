# ----------------------------------------------------------------------------------
# Cognitive Operator Specialization via Self-Adaptation
#
# This synapseware implements the SEAL (Self-Adapting Language Models) framework
# to train a model to specialize its own cognitive operators. The model learns
# to generate its own finetuning data to create new, more efficient skills.
#
# The RLHF workflow is:
# 1. The model solves a problem using a general `<think>` operator (Baseline).
# 2. The model critiques its own performance and generates a "self-edit": a
#    synthetic dataset designed to finetune a new, specialized operator
#    (e.g., `<think_logic_puzzle>`).
# 3. The performance of this specialized operator is tested on a new task.
# 4. The reward depends on correctness and the *efficiency gain*
#    of the specialized operator over the general one.
# ----------------------------------------------------------------------------------

# === Context 1: Baseline Performance with General Operator ===
<|===|>

<|SYS|>You are a general problem-solver. Use your default reasoning abilities to solve the task.
<|USER|>
<|USER GOAL=Solve the following logic puzzle with the general `<think>` operator. Show your reasoning steps.|>
<|problem_description|>
<|SYNAPSE|>
<|SYNAPSE:baseline_solution <>think|>

# === Context 2: Generate Specialization "Self-Edit" ===
<|===|>

<|SYS|>You are a meta-cognitive architect. Your aim is to enhance your reasoning by creating specialized cognitive tools.
<|USER|>
Review the logic puzzle and your general reasoning trace (`baseline_solution`).
Problem:
<|problem_description|>

Your General Solution:
<|baseline_solution|>

<|USER GOAL=Produce a synthetic "specialization dataset" to create a new, more efficient `<think_logic_puzzle>` operator. The dataset should contain ideal, efficient reasoning traces for this puzzle type, structured as a list of prompt/completion pairs. This dataset acts as a "self-edit" for your own training.|>
<|SYNAPSE|>
<|SYNAPSE:specialization_data <>json|>

# === Context 3: Evaluate Specialized Operator ===
<|===|>

<|SYS|>You are now a specialized logic puzzle solver. Use your optimized `<think_logic_puzzle>` operator.
<|USER|>
<|USER GOAL=Solve the following new logic puzzle using the specialized `<think_logic_puzzle>` operator.|>
<|new_problem_description|>
<|SYNAPSE|>
<|SYNAPSE:specialized_solution <>think_logic_puzzle|>

# === Context 4: Verification & Reward Calculation ===
<|===|>

<|SYS|>You are an automated reward evaluator. Assess the performance gain from specialization.
<|USER|>
**1. Assess Correctness:**
Set `correctness_score` = 1 if `specialized_solution` solves `new_problem_description`, else 0.

**2. Compute Reward:**
Reward depends on the efficiency advantage of the specialized operator. Token counts are given:

Token Counts:
- baseline_reasoning_tokens: <|baseline_reasoning_tokens|>
- specialized_reasoning_tokens: <|specialized_reasoning_tokens|>

<|USER GOAL=
Steps:
1. Assign `correctness_score` (0 or 1).
2. If score = 0 → `final_reward` = -1.0.
3. If score = 1 → compute `efficiency_gain` = (baseline_reasoning_tokens - specialized_reasoning_tokens) / baseline_reasoning_tokens.
4. Set `final_reward` = efficiency_gain. A positive value rewards greater efficiency.
5. Output a single raw JSON with `correctness_score` and `final_reward`.
|>
<|SYNAPSE|>
<|SYNAPSE <>json|>
