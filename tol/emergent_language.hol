# ----------------------------------------------------------------------------------
# Emergent Language Bootstrapping
#
# This synapseware trains a model to invent domain-specific, disposable
# micro-languages on demand to solve problems more efficiently.
# It formalizes the art of designing effective notation, making it a
# skill that can be learned and optimized.
#
# The RLHF workflow is:
# 1. Generate a baseline solution in English.
# 2. Invent a symbolic language tailored to the problem.
# 3. Solve the problem using that invented language.
# 4. Translate the solution back into English.
# 5. An evaluator checks correctness and computes a reward
#    based on token efficiency compared with the baseline.
#
# Rewards reflect the efficiency of the entire process compared
# to solving the problem directly. A reward > 1.0 means the abstraction worked.
# ----------------------------------------------------------------------------------

# === Context 1: Baseline Solution ===
<|===|>

<|SYS|>You are a precise, expert problem-solver. Solve the given problem directly and clearly in natural language.
<|USER|>
<|USER GOAL=Provide a direct English solution. This will serve as the baseline for correctness and efficiency.|>
<|problem_description|>
<|SYNAPSE|>
<|SYNAPSE:baseline_solution <>baseline|>


# === Context 2: Language Invention ===
<|===|>

<|SYS|>You are an expert in linguistics, symbolic reasoning, and problem decomposition. Invent a hyper-compact, domain-specific micro-language optimized for token efficiency to solve a given problem.
<|USER|>
<|USER GOAL=Create a language tailored to the problem. Define grammar and symbols that map directly to the problem's objects and actions. Provide a specification.|>
<|problem_description|>
<|SYNAPSE|>
<|SYNAPSE:language_spec <>language|>

# === Context 3: Solve in Invented Language ===
<|===|>

<|SYS|>You are an expert solver. Given a problem and a custom micro-language, solve the problem strictly using the invented language. Stay within its grammar and produce the most efficient symbolic solution.
<|USER|>
<|USER GOAL=Solve the problem using the invented language only. The solution must be purely symbolic.|>
Problem:
<|problem_description|>

Language Specification:
<|language_spec|>
<|SYNAPSE|>
<|SYNAPSE:solution_encoded <>solution|>

# === Context 4: Translate Solution to English ===
<|===|>

<|SYS|>You are an expert translator of symbolic and specialized languages. Translate a solution expressed in the invented language back into clear, comprehensive English.
<|USER|>
<|USER GOAL=Decompress the symbolic solution into natural English, preserving all details.|>
Language Specification:
<|language_spec|>

Encoded Solution:
<|solution_encoded|>
<|SYNAPSE|>
<|SYNAPSE:solution_decoded <>english_solution|>

# === Context 5: Verification & Reward Calculation ===
<|===|>

<|SYS|>You are a strict reward-calculation engine. Compare a baseline solution with the invented-language solution and output correctness and efficiency in JSON only.
<|USER|>
**1. Assess Correctness:**
Compare both solutions.  
Set `correctness_score` = 1 if `solution_decoded` matches `baseline_solution` semantically and fully solves the problem.  
Otherwise, set it = 0.

Baseline Solution (`baseline_solution`):
<|baseline_solution|>

Decoded Solution (`solution_decoded`):
<|solution_decoded|>

**2. Compute Reward:**
Using the correctness score and token counts:

Token Counts:
- baseline_tokens: <|baseline_tokens|>
- invention_tokens: <|invention_tokens|>
- encoded_solution_tokens: <|encoded_solution_tokens|>
- decoded_solution_tokens: <|decoded_solution_tokens|>

<|USER GOAL=
Steps:
1. Assign `correctness_score` = 1 or 0.
2. If score = 0, set `final_reward` = -1.0 and `efficiency_ratio` = 0.0.
3. If score = 1, compute `efficiency_ratio` = baseline_tokens / (invention_tokens + encoded_solution_tokens + decoded_solution_tokens).
   Then set `final_reward` = efficiency_ratio.
4. Output a single raw JSON with: `correctness_score` (int), `efficiency_ratio` (float), `final_reward` (float).
|>
<|SYNAPSE|>
<|SYNAPSE <>json|>
